{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the HRS index to find similar statutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.feature_extraction import dict_vectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Load in the index JSON file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = json.load(open('../data/hrs.index.statutes.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We'll use the stopwords from nltk as a list of common english words to filter out__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopword_set = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For ever row in the index JSON file, collect all the keywords, remove stopwords, and create a mapping between statute -> keywords__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statute_to_keywords = {}\n",
    "\n",
    "for row in index:\n",
    "    statutes = row[-1]\n",
    "    keywords = row[:-1]\n",
    "    \n",
    "    for statute in statutes:\n",
    "        statute_to_keywords[statute] = set(gensim.utils.simple_preprocess(\"\\n\".join(keywords))) - stopword_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17875"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(statute_to_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Here, we're going to convert the statue->keywords mapping into a statute-keyword matrix using scikit's DictVectorizer class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keys = []\n",
    "dicts = []\n",
    "\n",
    "for key, keyword_set in statute_to_keywords.items():\n",
    "    keys.append(key)\n",
    "    dicts.append( { k:True for k in keyword_set } )\n",
    "    \n",
    "m = dict_vectorizer.DictVectorizer().fit_transform(dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Now with the statute-keyword matrix, we'll compute all the pair-wise Jaccard distances between all of the statutes (takes a few minutes)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richard/miniconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype float64 was converted to bool by check_pairwise_arrays.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31min 12s, sys: 18.8 s, total: 31min 31s\n",
      "Wall time: 31min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dist = pairwise_distances(m.todense(), metric='jaccard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17875, 17875)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We're left with a full-rank distance matrix, so for each row we can find the columns with the smallest distances, which correspond to the most 'similar' statutes__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the diagonal of the distance matrix are all zeros (because the distance from a statute to itself is zero)\n",
    "# so we'll fill the diagonal with nans so those cells will sort to the last spots\n",
    "np.fill_diagonal(dist, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to numpy array for easier indexing\n",
    "keys = np.array(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sort each row of the distance matrix, and only keep the statutes with the 10 smallest distances__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "similar_top10 = {}\n",
    "\n",
    "for i, row in enumerate(dist):\n",
    "    mask = ~(row == 1.) # mask out entries that had exactly nothing in common\n",
    "    idx = np.argsort(row[mask]) # sort the row and keep the ordered index\n",
    "    similar_top10[keys[i]] = list(keys[mask][idx][:10]) # fill the statute->similar mapping with the top 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Save to file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json.dump(similar_top10,open('top_ten.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"397-11\": [\"396-13\", \"397-5\", \"431:2-209\", \"397-6\", \"397-1\", \"397-12\", \"397-2\", \"397-10\", \"397-8\", \"397-9\"], \"4605-23.5\": [\"46OJ-21\", \"4605-19\", \"4605-12\", \"4605-25\", \"460J-19\", \"46OJ-20\", \"4605-22\", \"46OJ-26\", \"46OJ-1\", \"4605-1\"], \"353-10.5\": [\"353-63.5\", \"353-17\", \"706-605.1\", \"657-14\", \"353-1\", \"353-26\", \"353-12\", \"706-672\", \"353-6\", \"354D-3\"], \"707-712.5\": [\"52D-8\", \"52D-6\", \"804-7.1\", \"52D-1"
     ]
    }
   ],
   "source": [
    "!head -c 400 top_ten.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
